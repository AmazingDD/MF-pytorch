<!--
 * @Author: Yu Di
 * @Date: 2019-08-07 17:05:30
 * @LastEditors: Yudi
 * @LastEditTime: 2019-08-16 11:27:55
 * @Company: Cardinal Operation
 * @Email: yudi@shanshu.ai
 * @Description: 
 -->

# recommend-algorithms

Sometimes, I just want reformat some state-of-the-art recommend algorithms with some new technique like Pytorch or tensorflow.

This repository contains algorithms below:

* `LR`: Logistc Regression

* `GMF`: [Probabilistic matrix factorization](https://www.asc.ohio-state.edu/statistics/dmsl//Salakhutdinov_Minh_2008.pdf)

* `BiasMF`: [Matrix Factorization Techniques for Recommender Systems](https://www.asc.ohio-state.edu/statistics/dmsl//Koren_2009.pdf)

* `SVDpp`: [Factorization meets the neighborhood: a multifaceted collaborative filtering model](https://dl.acm.org/citation.cfm?id=1401890.1401944)

* `NCF`: [Neural Collaborative Filtering](http://dl.acm.org/citation.cfm?id=3052569)

* `FM`: [Factorization Machine](https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf)

* `FFM`: [Field-aware Factorization Machines for CTR Prediction](https://www.csie.ntu.edu.tw/~cjlin/papers/ffm.pdf)

* `FsNN`: [Deep Learning over Multi-field Categorical Data: A Case Study on User Response Prediction](https://arxiv.org/abs/1601.02376)

* `WaD`: [Wide & Deep Learning for Recommender Systems](https://arxiv.org/abs/1606.07792)

* `AFM`: [Attentional Factorization Machines: Learning the Weight of Feature Interactions via Attention Networks](https://arxiv.org/abs/1708.04617)

* `NeuFM`: [Neural Factorization Machines for Sparse Predictive Analytics](https://arxiv.org/abs/1708.05027)

* `FNeuFM`: [Field-aware Neural Factorization Machine for Click-Through Rate Prediction](https://arxiv.org/abs/1902.09096)

* `DeepFM`: [DeepFM: A Factorization-Machine based Neural Network for CTR Prediction](https://arxiv.org/abs/1703.04247)

* `xDeepFM`: [xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems](https://arxiv.org/abs/1803.05170)

* `AutoInt`: [AutoInt: Automatic Feature Interaction Learning via Self-Attentive Neural Networks](https://arxiv.org/abs/1810.11921)
